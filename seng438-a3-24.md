**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      |  24   |
| -------------- | --- |
| Student Names: |  Ella Boulanger   |
|                |  Kenzie Fjestad   |
|                |  Raina Jugdev   |
|                |  Dominico Mendes   |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

In this lab, we further developed our understanding of software testing by developing white box test cases to evaluate different code coverages. Our goal was to utilize the content covered in lecture to gain practical experience with white box testing.

# 2 Manual data-flow coverage calculations for X and Y methods

## Data-flow coverage calculations
#### Range.contains():
#### DataUtilities.calculateColumnTotal(): 

= DU-pairs tested / total DU-pairs 
= 17 / 28 = 60.71% DU pair coverage

### Work for 3.2 of the Lab Instructions
#### 3.2.1 and 3.2.2 Data Flow Graph and def-use pairs labelled at every node

#### DataUtilities.calculateColumnTotal():
![alt text](https://github.com/seng438-winter-2024/seng438-a3-dominico25/blob/main/DataUtilitiesDFG.jpg?raw=true)



#### 3.2.3 DU-pairs per variable

#### Range.contains()
| **Variable** | **DU-pairs**  |
|----------------|----------|
| this.lower | (0, 1), (0, 2) |
| this.upper | (0, 1), (0, 2) |
| value | (0, 1), (0, 2) |

#### DataUtilities.calculateColumnTotal()
| **Variable** | **DU-pairs**  |
|----------------|----------|
| data | (0, 1), (0, 2), (0, 7), (0, 12) |
| column | (0, 7), (0, 12) |
| total | (2, 9), (2, 14), (9, 9), (14, 14) |
| rowCount | (3, 5), (3, 11) |
| n | (7, 8), (7, 9), (12, 13), (12, 14) |
| r | (4, 5), (4, 7), (4, 10), (10, 10), (10, 8), (10, 9) |
| r2 | (6, 11), (6, 12), (6, 15), (15, 15), (15, 11), (15, 12) |

#### 3.2.4 Test cases and the pairs covered

#### Range.contains(double)
| **Test Case** | **DU-pairs covered**  |
|----------------|----------|
| testInRangeValueForMethodContains() | (0, 1), (0, 2) |
| testPositiveOutOfRangeValueForMethodContains() | (0, 1), (0, 2) |
| testNegativeOutOfRangeValueForMethodContains() | (0, 1), (0, 2) |
| testBelowUpperBoundaryForMethodContains() | (0, 1), (0, 2) |
| testEqualToUpperBoundaryForMethodContains() | (0, 1), (0, 2) |
| testAboveUpperBoundaryForMethodContains() | (0, 1), (0, 2) |
| testBelowLowerBoundaryForMethodContains() | (0, 1), (0, 2) |
| testEqualToLowerBoundaryForMethodContains() | (0, 1), (0, 2) |
| testAboveLowerBoundaryForMethodContains() | (0, 1), (0, 2) |
| testNominalValueForMethodContains() | (0, 1), (0, 2) |

#### DataUtilities.calculateColumnTotal()
| **Test Case** | **DU-pairs covered**  |
|----------------|----------|
| testCalculateColumnTotalForTwoValues() | (0, 1), (0, 2), (0, 7), (0, 7), (2, 9), (9, 9), (3, 5), (3, 11), (7, 8), (7, 9), (4, 5), (4, 7), (4, 10), (10, 10), (10, 8), (10, 9), (6, 11) |
| testCalculateColTotalForNegativeValues() | (0, 1), (0, 2), (0, 7), (0, 7), (2, 9), (9, 9), (3, 5), (3, 11), (7, 8), (7, 9), (4, 5), (4, 7), (4, 10), (10, 10), (10, 8), (10, 9), (6, 11) |
| testCalcColNullDataThrowsException() | (0, 1) |
| testCalcColumnNullObject() | (0, 1) |



# 3 A detailed description of the testing strategy for the new unit test


We used white-box testing to develop our new unit tests and improve the code coverage of our test suite. Our testing strategy started with analyzing the source code that we now have access to. We also ran our existing tests using the “run as coverage” functionality from the Eclipse EclEmma code coverage tool. The coverage metrics provided an understanding of the areas in the code that our existing tests were not thoroughly covering. Using the line, branch, and method coverage measurements and the goal percentages that needed to be met, we were able to identify the unit tests that needed to be added to our suite. Our team split up to work in detail with the different classes that needed to be tested. The White-box testing strategy changed how we went about writing unit tests. When going into detail with specific methods in the two classes, we were able to see exactly what lines were being missed, and the code that would need to execute in order to reach them. The source code gave us insight into the internal structure of the methods being tested. Using this information we were able to develop specific tests that cater to the different coverages we were measuring. An example of this strategy is identifying the decision points in a method that were missing coverage for a side of the branch. When locating this, we can then write a unit test that should enter that specific piece of logic and satisfy the condition, increasing the branch coverage of our test suite. This strategy was repeated and modified for each coverage type, creating a comprehensive set of unit tests that thoroughly cover the provided classes.


# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

1. One test that was added to the DataUtilitiesTest file that increased the code coverage of the DataUtilities class was testGetCumulativePercentages_AllNullValues(). This test case targets the getCumulativePercentage(KeyedValues data) function, specifically parts of the function that deal with null values within the KeyedValues object that is taken in as an arguement. This was achieved by setting up a KeyedValues mock with 3 items of valid keys and values of null. Passing this object into the function increased branch coverage by hitting the "False" for most if/else statements within the function.

2. Another test that was added to the DataUtilitiesTest file that increased code coverage was the testEqual_SameContent() function. This test case targets the equal(double[][] a, double[][] b) function. This test case creates two new double[][] objects which contain the same content then passes those objects to the function. This tess is designed to hit the "False" on the first three if statements, then enetering the for loop but hitting the negative on the if statement within the loop. This function was not included in the Javadoc documentation that we initially used to write the test cases for this class in assignment 2, therefor this increased method coverage by 100%, branch coverage by ~50% and line coverage by ~60%. Eveything that this test case covered was an improvement to the original reported coverage.

3. One test that was added to the RangeTest file that increased the code coverage of the Range class was the testNegativeUpperBoundaryExpansionForMethodExpand() function. This test case targets the expand(Range range, double lowerMargin, double upperMargin) function for the Range class. It specifically targets the situation when upperMargin is a negative integer. This test was designed so that it would enter the if statement to allow for 100% statement coverage and 50% branch coverage for the function. This function was not previously chosen to be tested in assignment 2, and therefore this test case increased the coverage of the Range class by 7.1%. Specifically, it increased line coverage by 6.7%, branch coverage by 1.2%, and function coverage by 4.3%.

4. Another test that was added to the RangeTest file that increased code coverage was the testValidRangesForMethodCombineIgnoringNaN() function. This test case targets the combineIgnoringNaN(Range range1, Range range2) function for the Range class. Specifically, it targets for the case where both input ranges are valid Range objects. By inputting 2 valid ranges for this test case, overall coverage increased by 3.4%. This function also uses the private functions min and max, so by creating a test case using 2 valid inputs, coverage for the functions combineIgnoringNan, min, and max was achieved. In specifics, line coverage increased by 10.1%, branch coverage increased by 8.5%, and function coverage increased by 13.1%.

5. A third test that was added to the RangeTest file that increased code coverage was the testValidRangesForMethodCombine() function. This test case targets the combine(Range range1, Range range2) function for the Range class. It specifically targets the case where 2 valid ranges are inputted. Using 2 valid ranges as inputs, both if statements are considered and the test case max of 50% branch coverage for this function is achieved along with a 71.4% line coverage for the function. Overall this test case increased the coverage of the Range class by 3.9%. Specifically there was an increase of 4.2% for line coverage, 2.4% for branch coverage, and 4.3% for function coverage.


# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

## Data Utilities
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113636112/b5b216e6-181a-496e-9898-de840379b785)

As seen in the images provided the overal class coverage percentages for our chosen metrics are:
    <br>Line coverage = 89.6% = ~90%
  <br>Branch coverage = 81.2%
  <br>Method Coverage = 100%
  
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113636112/5d6e2581-5ee7-4ced-8776-312729b400cd)

### Methods with 100% coverage on all three chosen metrics (Line, Branch, Method):
  <br>clone(double[][])
  <br>createNumberArray(double[])
  <br>createNumberArray2D(double[][])
  <br>equal(double[][], double[][])
  <br>calculateRowTotal(Values2D, int, int[])
<br>
### Methods without 100% coverage on all three chosen metrics (Line, Branch, Method):
#### calculateColumnTotal(Values2D, int)
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113636112/85587e9d-c22f-4b4c-964d-1fea451bc804)

#### calculateRowTotal(Values2D, int)
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113636112/148bb45d-4d26-45c4-9269-64b41157d2a7)

#### getCumulatievPercentage(KeyedValues)
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113636112/c86f5283-7b5f-438f-ae50-73e67a9fa1d4)

#### calculateColumnTotal(Values2D, int, int[])
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113636112/74e272b7-9432-492e-8808-58a6f6c739eb)









## Range
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/2e78701d-c2b9-42ae-a420-a24149c24d70)

As seen in the images provided the overall class coverage percentages for our chosen metrics are:
    <br>Line coverage = 91.6%
  <br>Branch coverage = 84.1%
  <br>Method Coverage = 100.0%

![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/c8e16fd9-6f96-436f-bd9d-1b058940442a)

### Methods with 100% coverage on all three chosen metrics (Line, Branch, Method):
  <br>combine(Range, Range)
  <br>combineIgnoringNaN(Range, Range)
  <br>expand(Range, double, double)
  <br>max(double, double)
  <br>min(double, double)
  <br>scale(Range, double)
  <br>shift(Range, double)
  <br>shift(Range, double, boolean)
  <br>shiftWithNoZeroCrossing(double, double)
  <br>Range(double, double)
  <br>constrain(double)
  <br>equalsObject(Object)
  <br>getCentralValue()
  <br>hashCode()
  <br>intersects(Range)
  <br>isNaNRange()
  <br>toString()
  
### Methods without 100% coverage on all three chosen metrics (Line, Branch, Method):
#### expandToInclude(Range, double)
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/4889e191-c033-47d5-9d57-5b3b106ca7fe)

#### contains(double)
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/cba32643-a6ea-4a20-a2a3-f9d959406964)

#### intersects(double, double)
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/48bfdaed-bc29-404b-a925-6dbe5481476a)

#### getLength()
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/f39ce998-fa56-412d-bd8a-34e3e02cc642)

#### getLowerBound()
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/d60d68e7-b39d-487f-b9df-fb846ddfc442)

#### getUpperBound()
![image](https://github.com/seng438-winter-2024/seng438-a3-dominico25/assets/113635234/685563db-8d9a-4a32-a68a-b7195f4029d2)


# 6 Pros and Cons of coverage tools used and Metrics you report

The coverage tool used to conduct our white-box testing is Eclipse's EclEmma. This tool was convenient as it was already installed with Eclipse and it was very intuitive to become familiar with. Another advantage to this coverage tool is that it showed exactly where in the code our tests were not covering. We could identify specific lines in methods that required further testing. A con of EclEmma is that it does not include reports for the condition coverage metric. We were considering recording condition coverage when improving our test suite, but we chose to use method coverage instead. This was partially due to EclEmma not supporting condition coverage, but also because of the positive features of method coverage. Method coverage focuses on testing the methods in code, and if they have been executed by unit tests. Method coverage was useful in our test development as it allowed us to target the methods that had not been properly tested by our existing tests. The other metrics we use are branch and line coverage. A pro of using branch coverage is that we could see how the code proceeds at every decision point within the tested methods. This ensures that our test suite extensively tests the logical decisions made in the classes being tested. Line coverage was useful in ensuring at a base level that our tests would get through the bulk of the source code. This meant that our tests would run through the largest amount of lines that we could possibly test in the given classes. A negative to line testing is that if certain lines in the code at hand cannot possibly be reached by properly written tests, the line coverage metric will suffer. 

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

An advantage of requirements-based testing is it allows for easily making test cases that test the functionality users want. One shortcoming of this is that well-documented requirements are needed to set up good test cases. Coverage-based testing allows us to make test cases that are able to get edge cases and specific scenarios of code execution. However, this type of testing comes at a high resource cost for executing these tests.

# 8 A discussion on how the team work/effort was divided and managed

Our team managed the work effort first by working all together to set up the testing environment on each individuals machines. Raina created the data flow graph for the method calculateColumnTotal because she was the most familiar with it. Domo created the other data flow graph for contains because he created the tests for it in the last assignment. Increasing code coverage of our test suite started with each person trying to increase the tests they created in the previous assignment. Once we had completed our tests we proceeded to start completing test cases for the Range Class methods that we had not done in the previous assignment. This got us to the necessary coverage milestones.

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Text…

# 10 Comments/feedback on the lab itself

We found this lab to be well organized and have a good workflow structure, we felt the work expectations were clear and had a good understanding of what was expected during the in lab demo. The supplementary powerpoint offered a good overview for the learning goals of the assignment.  We gained a better understanding of white box testing and how to use the JUnit framework. Overall this was an enjoyable lab that was understandable and easy to work on in a group.
